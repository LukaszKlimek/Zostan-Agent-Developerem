# ğŸ“‰ Pochodne i CaÅ‚ki dla AI Engineering


---

## ğŸ¯ Po co mi to w AI?

| Gdzie w AI? | Co tam robi rachunek rÃ³Å¼niczkowy? |
|-------------|----------------------------------|
| Trening sieci neuronowych | Gradient descent â€” minimalizacja bÅ‚Ä™du |
| Backpropagation | Obliczanie gradientÃ³w warstw sieci |
| Optymalizacja | Szukanie minimum funkcji straty |
| Regularyzacja | Gradient normy wag |
| Learning rate | Jak duÅ¼y krok wzdÅ‚uÅ¼ gradientu |

**Pochodna = kierunkowskaz w procesie uczenia siÄ™ modelu AI!**

---

## 1ï¸âƒ£ CZYM JEST POCHODNA?

### Intuicja: prÄ™dkoÅ›Ä‡ zmiany

Pochodna odpowiada na pytanie: **"Jak szybko zmienia siÄ™ funkcja w danym punkcie?"**

PrzykÅ‚ad Å¼yciowy:
```
Jedziesz samochodem.
Pozycja = f(czas)

PrÄ™dkoÅ›Ä‡ = POCHODNA pozycji wzglÄ™dem czasu
         = jak szybko zmienia siÄ™ pozycja
```

### Geometryczna intuicja

Pochodna w punkcie = **nachylenie stycznej** do wykresu w tym punkcie.

```
y
â”‚              /â† styczna (tangent)
â”‚           __/
â”‚        __/
â”‚     __/ â† funkcja f(x)
â”‚  __/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
         â†‘
    w tym punkcie pochodna = nachylenie tej stycznej
```

### Definicja

```
         f(x + h) - f(x)
f'(x) = lim â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        hâ†’0       h
```

Prosto mÃ³wiÄ…c: jak zmienia siÄ™ `f(x)` gdy `x` zmienia siÄ™ o bardzo maÅ‚y krok `h`.

---

## 2ï¸âƒ£ PODSTAWOWE REGUÅY RÃ“Å»NICZKOWANIA

Nie trzeba znaÄ‡ ich wszystkich na pamiÄ™Ä‡, ale warto rozumieÄ‡ wzorce.

### Pochodna staÅ‚ej

```
f(x) = 5    â†’    f'(x) = 0

Intuicja: staÅ‚a siÄ™ nie zmienia, wiÄ™c "prÄ™dkoÅ›Ä‡ zmiany" = 0
```

### Pochodna potÄ™gi (Power Rule)

```
f(x) = xâ¿    â†’    f'(x) = nÂ·xâ¿â»Â¹

PrzykÅ‚ady:
  f(x) = xÂ²    â†’    f'(x) = 2x
  f(x) = xÂ³    â†’    f'(x) = 3xÂ²
  f(x) = x     â†’    f'(x) = 1
```

### Pochodna sumy

```
(f + g)' = f' + g'

PrzykÅ‚ad:
  f(x) = xÂ² + 3x + 5
  f'(x) = 2x + 3 + 0 = 2x + 3
```

### ReguÅ‚a Å‚aÅ„cuchowa (Chain Rule) â€” KLUCZOWA!

JeÅ›li mamy zÅ‚oÅ¼enie funkcji: `f(g(x))`

```
[f(g(x))]' = f'(g(x)) Â· g'(x)

"Pochodna zewnÄ™trzna Ã— pochodna wewnÄ™trzna"
```

**PrzykÅ‚ad:**
```
h(x) = (2x + 1)Â²

ZewnÄ™trzna: f(u) = uÂ²    â†’  f'(u) = 2u
WewnÄ™trzna: g(x) = 2x+1  â†’  g'(x) = 2

h'(x) = 2(2x+1) Â· 2 = 4(2x+1) = 8x + 4
```

> ğŸ’¡ **W AI:** ReguÅ‚a Å‚aÅ„cuchowa to podstawa **backpropagation** â€” algorytmu uczenia sieci neuronowych!

---

## 3ï¸âƒ£ GRADIENT â€” POCHODNA DLA WIELU ZMIENNYCH

### Czym jest gradient?

Gdy funkcja ma wiele zmiennych, zamiast pochodnej mamy **gradient** â€” wektor pochodnych czÄ…stkowych.

```
f(xâ‚, xâ‚‚) = xâ‚Â² + xâ‚‚Â²

âˆ‚f/âˆ‚xâ‚ = 2xâ‚   â† pochodna czÄ…stkowa po xâ‚
âˆ‚f/âˆ‚xâ‚‚ = 2xâ‚‚   â† pochodna czÄ…stkowa po xâ‚‚

âˆ‡f = [2xâ‚, 2xâ‚‚]  â† gradient (wektor)
```

### Intuicja geometryczna gradientu

```
        GÃ³ra (maximum)
           *
          â†—â†‘â†–
         â†— â†‘ â†–     â† gradient wskazuje
        â†—  â†‘  â†–       kierunek NAJSZYBSZEGO
       â†—   â†‘   â†–      WZROSTU funkcji
      â†—    â†‘    â†–
     â†—     â†‘     â†–
```

**WaÅ¼na wÅ‚aÅ›ciwoÅ›Ä‡:**
- Gradient wskazuje kierunek **najszybszego wzrostu**
- `-gradient` wskazuje kierunek **najszybszego spadku**

---

## 4ï¸âƒ£ GRADIENT DESCENT â€” SERCE TRENOWANIA AI

### Idea algorytmu

Chcemy znaleÅºÄ‡ **minimum** funkcji straty (loss function).

```
ALGORYTM:
1. Zacznij w losowym miejscu
2. Oblicz gradient (w ktÃ³rym kierunku jest "pod gÃ³rÄ™")
3. ZrÃ³b krok w PRZECIWNYM kierunku (pod gÃ³rÄ™ przeciwnie = w dÃ³Å‚!)
4. Powtarzaj aÅ¼ dojdziesz do minimum
```

**Wizualnie:**
```
Loss
â”‚\
â”‚ *  â† start (losowe wagi)
â”‚  \
â”‚   \
â”‚    *  â† po kroku 1
â”‚     \
â”‚      \
â”‚       *  â† po kroku 2
â”‚        â”€â”€â”€â”€â”€â”€*  â† minimum (najlepsze wagi)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ parametry modelu
```

### WzÃ³r aktualizacji wag

```
w_nowe = w_stare - Î· Â· âˆ‡L(w)

gdzie:
  w = wagi modelu
  Î· = learning rate (krok uczenia)
  âˆ‡L = gradient funkcji straty
```

### Rola learning rate

```
Î· zbyt maÅ‚e:          Î· zbyt duÅ¼e:         Î· w sam raz:

â”‚\                    â”‚\                   â”‚\
â”‚ \                   â”‚  *                 â”‚ \
â”‚  \                  â”‚   *               â”‚  \
â”‚   *                 â”‚  *                â”‚   *
â”‚   *                 â”‚ *                 â”‚    *
â”‚   *                 â”‚*                  â”‚     â”€â”€*
â”‚   *                 â”‚nadskakuje!        â”‚
â”‚ zbyt wolno!                             â”‚ dobry!
```

---

## 5ï¸âƒ£ BACKPROPAGATION â€” REGULA ÅAÅƒCUCHOWA W AKCJI

### SieÄ‡ neuronowa jako zÅ‚oÅ¼enie funkcji

```
WejÅ›cie x
    â†“
[Warstwa 1: hâ‚ = fâ‚(Wâ‚Â·x + bâ‚)]
    â†“
[Warstwa 2: hâ‚‚ = fâ‚‚(Wâ‚‚Â·hâ‚ + bâ‚‚)]
    â†“
[WyjÅ›cie: Å· = fâ‚ƒ(Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ)]
    â†“
[Strata: L = loss(Å·, y)]
```

Chcemy: `âˆ‚L/âˆ‚Wâ‚`, `âˆ‚L/âˆ‚Wâ‚‚`, `âˆ‚L/âˆ‚Wâ‚ƒ` â€” jak zmieniÄ‡ wagi?

### Backpropagation to reguÅ‚a Å‚aÅ„cuchowa wstecz

```
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚Å· Â· âˆ‚Å·/âˆ‚hâ‚‚ Â· âˆ‚hâ‚‚/âˆ‚hâ‚ Â· âˆ‚hâ‚/âˆ‚Wâ‚
           â†‘          â†‘         â†‘         â†‘
        ostatnia    3. warstwa  2. warstwa  1. warstwa
        warstwa
```

KaÅ¼dy wspÃ³Å‚czynnik to pochodna jednej warstwy â€” liczymy je **od tyÅ‚u** (stÄ…d "back" propagation).

---

## 6ï¸âƒ£ CAÅKI â€” SKRÃ“TOWE WPROWADZENIE

CaÅ‚ka jest "odwrotnoÅ›ciÄ…" pochodnej.

### Intuicja geometryczna

CaÅ‚ka = **pole pod wykresem funkcji**

```
y
â”‚        â–ˆâ–ˆâ–ˆâ–ˆ
â”‚      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
  a                b

CaÅ‚ka od a do b = pole zacieniowanego obszaru
```

### Podstawowy wzÃ³r

```
âˆ« xâ¿ dx = xâ¿âºÂ¹/(n+1) + C

PrzykÅ‚ady:
  âˆ« 2x dx = xÂ² + C
  âˆ« 3xÂ² dx = xÂ³ + C
  âˆ« 1 dx = x + C
```

### Gdzie caÅ‚ki pojawiajÄ… siÄ™ w AI?

```
WartoÅ›Ä‡ oczekiwana (expected value):
  E[X] = âˆ« x Â· p(x) dx

  â†’ Jak "Å›rednia waÅ¼ona" dla zmiennych ciÄ…gÅ‚ych
  â†’ Podstawa teorii prawdopodobieÅ„stwa w ML

Entropia (miara niepewnoÅ›ci):
  H(p) = -âˆ« p(x) Â· log(p(x)) dx

  â†’ Metryka w modelach probabilistycznych
```

---

## ğŸ“Œ Podsumowanie

| PojÄ™cie | Co to? | Po co w AI? |
|---------|--------|-------------|
| **Pochodna** | PrÄ™dkoÅ›Ä‡ zmiany funkcji | Kierunek optymalizacji |
| **ReguÅ‚a Å‚aÅ„cuchowa** | Pochodna zÅ‚oÅ¼enia funkcji | Backpropagation |
| **Gradient** | Wektor pochodnych czÄ…stkowych | Gradient descent |
| **Gradient descent** | Algorytm minimalizacji | Trening modeli ML |
| **Learning rate (Î·)** | Rozmiar kroku optymalizacji | Sterowanie treningiem |
| **CaÅ‚ka** | Pole pod wykresem | WartoÅ›Ä‡ oczekiwana, entropia |

### Wielkie rÃ³wnanie trenowania modelu

```
Nowe wagi = Stare wagi - learning_rate Ã— gradient_straty

W kaÅ¼dym kroku trenowania sieÄ‡ "sprawdza gradient"
i koryguje swoje wagi, Å¼eby popeÅ‚niaÄ‡ mniejszy bÅ‚Ä…d.
```

---

## âœ… SprawdÅº siÄ™

1. âœ… Jaka jest pochodna funkcji `f(x) = xÂ³`?
2. âœ… Co wskazuje gradient funkcji wielu zmiennych?
3. âœ… Co siÄ™ stanie, gdy learning rate jest zbyt duÅ¼y?
4. âœ… Jak reguÅ‚a Å‚aÅ„cuchowa wiÄ…Å¼e siÄ™ z backpropagation?

<details>
<summary>Odpowiedzi</summary>

1. `f'(x) = 3xÂ²`
2. Gradient wskazuje kierunek **najszybszego wzrostu** funkcji (uÅ¼ywamy -gradient do zejÅ›cia w dÃ³Å‚)
3. Model bÄ™dzie "przeskakiwaÄ‡" przez minimum i moÅ¼e nigdy nie osiÄ…gnÄ…Ä‡ dobrego rozwiÄ…zania
4. Backpropagation stosuje reguÅ‚Ä™ Å‚aÅ„cuchowÄ… wielokrotnie od koÅ„ca sieci do poczÄ…tku, obliczajÄ…c gradienty kaÅ¼dej warstwy

</details>

---

Pochodne i gradienty to silnik, ktÃ³ry napÄ™dza uczenie maszynowe. KaÅ¼dy model, ktÃ³ry "uczy siÄ™ z danych", uÅ¼ywa tych konceptÃ³w do minimalizowania bÅ‚Ä™dÃ³w!
