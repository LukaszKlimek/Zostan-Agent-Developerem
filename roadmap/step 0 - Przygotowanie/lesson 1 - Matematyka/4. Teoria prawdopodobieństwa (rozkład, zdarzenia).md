# ğŸ² Teoria PrawdopodobieÅ„stwa

---

# CZÄ˜ÅšÄ† I: MATEMATYKA

---

## 1ï¸âƒ£ CO TO JEST PRAWDOPODOBIEÅƒSTWO?

### Intuicja

PrawdopodobieÅ„stwo mÃ³wi nam, **jak bardzo moÅ¼liwe jest jakieÅ› zdarzenie**.

Intuicyjnie wszyscy to rozumiemy:
- "Jutro bÄ™dzie deszcz â€” prawie na pewno, jest ciemno i pochmurno"
- "WyrzucÄ™ szÃ³stkÄ™ â€” nie wiem, moÅ¼e mi siÄ™ uda"
- "WyjdÄ™ przez Å›cianÄ™ â€” niemoÅ¼liwe"

Matematyka nadaje tym odczuciom konkretne liczby.

### Definicja

PrawdopodobieÅ„stwo zdarzenia to liczba z przedziaÅ‚u [0, 1]:

```
P(zdarzenie) âˆˆ [0, 1]

P = 0    â†’ zdarzenie niemoÅ¼liwe (absolutnie nigdy siÄ™ nie zdarzy)
P = 0.1  â†’ zdarzenie maÅ‚o prawdopodobne (1 na 10)
P = 0.5  â†’ zdarzenie rÃ³wnie prawdopodobne co niemoÅ¼liwe (50/50)
P = 0.9  â†’ zdarzenie bardzo prawdopodobne (9 na 10)
P = 1    â†’ zdarzenie pewne (zawsze siÄ™ zdarzy)
```

MoÅ¼emy teÅ¼ wyraÅ¼aÄ‡ prawdopodobieÅ„stwo w procentach â€” P = 0.7 to 70%.

---

## 2ï¸âƒ£ PODSTAWOWE POJÄ˜CIA

### DoÅ›wiadczenie losowe

**DoÅ›wiadczenie losowe** to czynnoÅ›Ä‡, ktÃ³rej wynik z gÃ³ry nie jest znany.

PrzykÅ‚ady:
- Rzut monetÄ…
- Rzut kostkÄ… szeÅ›cioÅ›ciennÄ…
- Wylosowanie karty z talii
- Losowe wybranie osoby z tÅ‚umu

### PrzestrzeÅ„ prÃ³bna Î©

**PrzestrzeÅ„ prÃ³bna** (oznaczana Î©, grecka litera omega) to zbiÃ³r **wszystkich moÅ¼liwych wynikÃ³w** doÅ›wiadczenia.

```
Rzut monetÄ…:       Î© = {orzeÅ‚, reszka}
Rzut kostkÄ…:       Î© = {1, 2, 3, 4, 5, 6}
PÅ‚eÄ‡ dziecka:      Î© = {dziewczynka, chÅ‚opiec}
Wynik meczu piÅ‚ki: Î© = {wygrana, remis, przegrana}
```

### Zdarzenie

**Zdarzenie** to dowolny podzbiÃ³r przestrzeni prÃ³bnej â€” czyli pewna czÄ™Å›Ä‡ moÅ¼liwych wynikÃ³w, o ktÃ³rej pytamy.

```
Rzut kostkÄ…: Î© = {1, 2, 3, 4, 5, 6}

Zdarzenie A = "wypadÅ‚a parzysta liczba"   = {2, 4, 6}
Zdarzenie B = "wypadÅ‚a liczba wiÄ™ksza niÅ¼ 4" = {5, 6}
Zdarzenie C = "wypadÅ‚a jedynka"          = {1}
Zdarzenie D = "wypadÅ‚a liczba < 10"      = {1,2,3,4,5,6} = Î©   â† zdarzenie pewne
Zdarzenie E = "wypadÅ‚o zero"             = {}  â† zdarzenie niemoÅ¼liwe
```

### Obliczanie prawdopodobieÅ„stwa

Gdy wszystkie wyniki sÄ… **jednakowo prawdopodobne** (uczciwa kostka, uczciwa moneta):

```
         liczba wynikÃ³w sprzyjajÄ…cych
P(A) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         liczba wszystkich wynikÃ³w

PrzykÅ‚ady:
  P(parzysta) = 3/6 = 1/2 = 0.5      (wyniki: 2, 4, 6 â†’ 3 z 6)
  P(liczba > 4) = 2/6 = 1/3 â‰ˆ 0.33   (wyniki: 5, 6 â†’ 2 z 6)
  P(jedynka) = 1/6 â‰ˆ 0.167
  P(liczba < 10) = 6/6 = 1            (wszystkie wyniki pasujÄ…)
  P(zero) = 0/6 = 0                   (Å¼aden wynik nie pasuje)
```

---

## 3ï¸âƒ£ PODSTAWOWE PRAWA RACHUNKU PRAWDOPODOBIEÅƒSTWA

### Prawo 1: Suma prawdopodobieÅ„stw przestrzeni prÃ³bnej = 1

```
P(Î©) = 1

Czyli: coÅ› ZAWSZE siÄ™ zdarzy.
```

### Prawo 2: Zdarzenie przeciwne

Zdarzenie "nie A" (oznaczane Aá¶œ lub Ä€) â€” to wszystko co nie naleÅ¼y do A.

```
P(A) + P(nie A) = 1
P(nie A) = 1 - P(A)

PrzykÅ‚ad:
  P(wypadnie parzysta) = 0.5
  P(NIE wypadnie parzysta) = 1 - 0.5 = 0.5

  P(wypadnie szÃ³stka) = 1/6
  P(NIE wypadnie szÃ³stka) = 1 - 1/6 = 5/6
```

### Prawo 3: Suma zdarzeÅ„ (A lub B)

```
P(A lub B) = P(A) + P(B) - P(A i B)

Dlaczego odejmujemy P(A i B)?
  Bo gdybyÅ›my dodali P(A) + P(B), wyniki naleÅ¼Ä…ce do OBU zdarzeÅ„
  liczylibyÅ›my dwa razy.
```

**PrzykÅ‚ad:**

```
Rzut kostkÄ…:
  A = "wypadÅ‚a parzysta" = {2, 4, 6},  P(A) = 3/6
  B = "wypadÅ‚a > 4"      = {5, 6},     P(B) = 2/6
  A i B = {6}  (parzysta I wiÄ™ksza niÅ¼ 4),  P(A i B) = 1/6

P(A lub B) = 3/6 + 2/6 - 1/6 = 4/6 = 2/3 â‰ˆ 0.667

Sprawdzenie: A lub B = {2, 4, 5, 6} â†’ 4 elementy â†’ 4/6 âœ…
```

### Prawo 4: Zdarzenia wykluczajÄ…ce siÄ™ (rozÅ‚Ä…czne)

Zdarzenia sÄ… **rozÅ‚Ä…czne** gdy nie mogÄ… zajÅ›Ä‡ jednoczeÅ›nie (majÄ… pustÄ… czÄ™Å›Ä‡ wspÃ³lnÄ…).

```
A i B rozÅ‚Ä…czne:   P(A lub B) = P(A) + P(B)   (bo P(A i B) = 0)

PrzykÅ‚ad: rzut kostkÄ…
  A = "wypadÅ‚a 1"  = {1}
  B = "wypadÅ‚a 6"  = {6}
  Nie mogÄ… zajÅ›Ä‡ jednoczeÅ›nie â†’ rozÅ‚Ä…czne

  P(A lub B) = P(1) + P(6) = 1/6 + 1/6 = 2/6 = 1/3
```

---

## 4ï¸âƒ£ PRAWDOPODOBIEÅƒSTWO WARUNKOWE

### Intuicja

WyobraÅº sobie: rzucasz kostkÄ…, ale kolega patrzy na wynik i mÃ³wi "wypadÅ‚a parzysta". Teraz pytasz: **"jakie jest prawdopodobieÅ„stwo, Å¼e wypadÅ‚a szÃ³stka, skoro wiem Å¼e wypadÅ‚a parzysta?"**

```
Bez informacji:     P(6) = 1/6 â‰ˆ 0.167
Z informacjÄ… "parzysta": P(6 | parzysta) = ?

Skoro wiemy Å¼e wypadÅ‚a parzysta, moÅ¼liwe wyniki to tylko: {2, 4, 6}
SpoÅ›rÃ³d tych, szÃ³stka to 1 przypadek na 3.
P(6 | parzysta) = 1/3 â‰ˆ 0.333
```

Wiedza o tym, Å¼e "wypadÅ‚a parzysta" **zmieniÅ‚a** nasze prawdopodobieÅ„stwo!

### Definicja

`P(A|B)` czytamy: "prawdopodobieÅ„stwo A pod warunkiem B" lub "prawdopodobieÅ„stwo A wiedzÄ…c Å¼e B zaszÅ‚o".

```
           P(A i B)
P(A|B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
             P(B)
```

**PrzykÅ‚ad z kostkÄ…:**

```
A = "wypadÅ‚a szÃ³stka" = {6},  P(A) = 1/6
B = "wypadÅ‚a parzysta" = {2,4,6},  P(B) = 3/6 = 1/2
A i B = {6},  P(A i B) = 1/6

P(A|B) = P(A i B) / P(B) = (1/6) / (1/2) = (1/6) Ã— 2 = 2/6 = 1/3  âœ…
```

### Bardziej Å¼yciowy przykÅ‚ad

```
W klasie 30 uczniÃ³w:
  20 osÃ³b lubi matematykÄ™
  15 osÃ³b lubi informatykÄ™
  10 osÃ³b lubi OBÄ„

P(lubi matematykÄ™ | lubi informatykÄ™) = ?

P(mat i inf) = 10/30 = 1/3
P(inf) = 15/30 = 1/2

P(mat | inf) = (1/3) / (1/2) = 2/3 â‰ˆ 0.667

Czyli wÅ›rÃ³d osÃ³b lubiÄ…cych informatykÄ™, 2/3 lubi teÅ¼ matematykÄ™.
```

---

## 5ï¸âƒ£ NIEZALEÅ»NOÅšÄ† ZDARZEÅƒ

### Kiedy zdarzenia sÄ… niezaleÅ¼ne?

Zdarzenia A i B sÄ… **niezaleÅ¼ne**, gdy wiedza o zajÅ›ciu jednego NIE zmienia prawdopodobieÅ„stwa drugiego.

```
Formalnie: P(A|B) = P(A)  (B nie zmienia prawdopodobieÅ„stwa A)

Co rÃ³wnowaÅ¼nie oznacza:
P(A i B) = P(A) Ã— P(B)
```

### PrzykÅ‚ady

**Zdarzenia niezaleÅ¼ne:**

```
Rzut dwoma rÃ³Å¼nymi kostkami.
  A = "pierwsza kostka wypadÅ‚a 6"
  B = "druga kostka wypadÅ‚a 6"

  Wynik pierwszej kostki NIE wpÅ‚ywa na wynik drugiej.

  P(A) = 1/6
  P(B) = 1/6
  P(A i B) = P(A) Ã— P(B) = 1/6 Ã— 1/6 = 1/36 âœ…
```

**Zdarzenia zaleÅ¼ne:**

```
Talia 52 kart. Losujemy kartÄ™, patrzymy na niÄ… i odkÅ‚adamy.
  A = "pierwsza karta to as"
  B = "druga karta to as"

  Po wylosowaniu asa (zdarzenie A) w talii pozostajÄ… tylko 3 asy na 51 kart.

  P(A) = 4/52 = 1/13
  P(B | A) = 3/51 = 1/17  â† INNE niÅ¼ P(B) = 4/52

  Zdarzenia ZALEÅ»NE! âŒ
```

---

## 6ï¸âƒ£ TWIERDZENIE BAYESA

### Problem

Twierdzenie Bayesa odpowiada na pytanie: **"Skoro obserwujÄ™ skutek, jakie jest prawdopodobieÅ„stwo danej przyczyny?"**

To pozwala nam **aktualizowaÄ‡ przekonania** na podstawie nowych informacji.

### Wyprowadzenie

Z definicji prawdopodobieÅ„stwa warunkowego:

```
P(A|B) = P(A i B) / P(B)
P(B|A) = P(A i B) / P(A)

Z drugiego rÃ³wnania: P(A i B) = P(B|A) Ã— P(A)
Podstawiamy do pierwszego:

                P(B|A) Ã— P(A)
P(A|B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                  P(B)
```

### Jak obliczaÄ‡ P(B)?

CzÄ™sto P(B) liczymy uÅ¼ywajÄ…c **peÅ‚nego prawdopodobieÅ„stwa**:

```
P(B) = P(B|A) Ã— P(A) + P(B|nie-A) Ã— P(nie-A)
```

### PeÅ‚ny przykÅ‚ad â€” test medyczny

Mamy test na rzadkÄ… chorobÄ™. Wiemy:
- Choroba dotyka 1% populacji: P(chory) = 0.01
- Test daje wynik pozytywny dla 99% chorych: P(+ | chory) = 0.99
- Test daje faÅ‚szywy wynik pozytywny u 5% zdrowych: P(+ | zdrowy) = 0.05

Pytanie: **JeÅ›li test wyszedÅ‚ pozytywny, jakie jest prawdopodobieÅ„stwo, Å¼e jestem naprawdÄ™ chory?**

```
A = "jestem chory"
B = "test wyszedÅ‚ pozytywny"

Chcemy: P(chory | test +) = P(A|B)

Krok 1: Oblicz P(B) = P(test +)
  P(B) = P(+|chory) Ã— P(chory) + P(+|zdrowy) Ã— P(zdrowy)
       = 0.99 Ã— 0.01 + 0.05 Ã— 0.99
       = 0.0099 + 0.0495
       = 0.0594

Krok 2: Zastosuj twierdzenie Bayesa
  P(chory | test+) = P(+|chory) Ã— P(chory) / P(B)
                   = 0.99 Ã— 0.01 / 0.0594
                   = 0.0099 / 0.0594
                   â‰ˆ 0.167

Wynik: Tylko 16.7% szansy Å¼e jesteÅ› chory, mimo pozytywnego testu!
```

**Dlaczego tak maÅ‚o?** Bo choroba jest rzadka (1%) i faÅ‚szywe alarmy sÄ… czÄ™ste. WÅ›rÃ³d 10000 osÃ³b:
- 100 faktycznie chorych, 99 z nich da wynik + (prawdziwie pozytywny)
- 9900 zdrowych, ale 495 z nich teÅ¼ da wynik + (faÅ‚szywie pozytywny)
- ÅÄ…cznie 594 wynikÃ³w pozytywnych, z czego tylko 99 to prawdziwe przypadki

---

## 7ï¸âƒ£ ROZKÅADY PRAWDOPODOBIEÅƒSTWA

RozkÅ‚ad prawdopodobieÅ„stwa opisuje, jak prawdopodobieÅ„stwo jest "rozÅ‚oÅ¼one" miÄ™dzy rÃ³Å¼ne moÅ¼liwe wyniki.

### RozkÅ‚ad jednorodny (Uniform)

Wszystkie wyniki sÄ… jednakowo prawdopodobne.

```
Rzut uczciwÄ… kostkÄ…:

P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1/6 â‰ˆ 0.167

Wizualnie:
â”‚
â”‚  â”€  â”€  â”€  â”€  â”€  â”€   â† wszystkie jednakowo wysokie
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1  2  3  4  5  6
```

### RozkÅ‚ad Bernoulliego

Opisuje doÅ›wiadczenie z **tylko dwoma wynikami**: sukces (1) lub poraÅ¼ka (0).

Jeden parametr: `p` = prawdopodobieÅ„stwo sukcesu.

```
P(X = 1) = p        â† sukces
P(X = 0) = 1 - p    â† poraÅ¼ka

PrzykÅ‚ady:
  Rzut monetÄ…:        p = 0.5    (orzeÅ‚ = sukces)
  StrzaÅ‚ do celu:     p = 0.7    (trafienie = sukces)
  Choroba (rzadka):   p = 0.01   (choroba = sukces? â€” tu "sukces" to po prostu "zdarzenie 1")
```

### RozkÅ‚ad Dwumianowy (Binomial)

Co jeÅ›li wykonujemy n niezaleÅ¼nych prÃ³b Bernoulliego i pytamy: "ile razy sukces?"

```
P(X = k) = C(n,k) Ã— páµ Ã— (1-p)â¿â»áµ

Gdzie:
  n = liczba prÃ³b
  k = liczba sukcesÃ³w, o ktÃ³rÄ… pytamy
  p = prawdopodobieÅ„stwo sukcesu w jednej prÃ³bie
  C(n,k) = n! / (k! Ã— (n-k)!)  = "n po k" = kombinacja
```

PrzykÅ‚ad: rzucam monetÄ… 4 razy, jakie jest P(dokÅ‚adnie 3 orÅ‚y)?

```
n=4, k=3, p=0.5

C(4,3) = 4!/(3!Ã—1!) = 24/(6Ã—1) = 4

P(X=3) = 4 Ã— 0.5Â³ Ã— 0.5Â¹ = 4 Ã— 0.125 Ã— 0.5 = 0.25 = 25%
```

### RozkÅ‚ad normalny (Gaussa) â€” NAJWAÅ»NIEJSZY!

RozkÅ‚ad normalny to najbardziej "naturalny" rozkÅ‚ad w przyrodzie. Wzrost ludzi, wyniki egzaminÃ³w, bÅ‚Ä™dy pomiarÃ³w â€” wiele zjawisk naturalnych ma rozkÅ‚ad normalny.

**KsztaÅ‚t:** krzywa dzwonowa, symetryczna

```
          â†‘
          â”‚        â•”â•â•â•â•â•â•â•—
          â”‚      â•”â•        â•šâ•—
          â”‚    â•”â•            â•šâ•—
          â”‚  â•”â•                â•šâ•—
          â”‚â•”â•                    â•šâ•—
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â†‘
                    Å›rednia Î¼
                    = mediana
                    = moda
```

**Dwa parametry:**
- `Î¼` (mu) = **Å›rednia** â€” gdzie jest centrum (Å›rodek dzwonu)
- `Ïƒ` (sigma) = **odchylenie standardowe** â€” jak szeroki jest dzwon

```
MaÅ‚y Ïƒ:            DuÅ¼y Ïƒ:
     â–ˆ                 â”‚
    â–ˆâ–ˆâ–ˆ                â”‚  âˆ©âˆ©âˆ©
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               â”‚ âˆ©   âˆ©
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              â”‚âˆ©     âˆ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(wÄ…ski, wysoki)    (szeroki, niski)
```

**ReguÅ‚a 68-95-99.7:** (bardzo waÅ¼na!)

```
68% danych leÅ¼y w przedziale   [Î¼ - Ïƒ,  Î¼ + Ïƒ]
95% danych leÅ¼y w przedziale   [Î¼ - 2Ïƒ, Î¼ + 2Ïƒ]
99.7% danych leÅ¼y w przedziale [Î¼ - 3Ïƒ, Î¼ + 3Ïƒ]

JeÅ›li wzrost PolakÃ³w ma Î¼ = 175 cm, Ïƒ = 10 cm:
  68% PolakÃ³w ma wzrost 165 - 185 cm
  95% PolakÃ³w ma wzrost 155 - 195 cm
```

---

## 8ï¸âƒ£ WARTOÅšÄ† OCZEKIWANA I WARIANCJA

### WartoÅ›Ä‡ oczekiwana E[X]

To "przeciÄ™tna wartoÅ›Ä‡" zmiennej losowej przy wielu powtÃ³rzeniach doÅ›wiadczenia.

```
Dla zmiennej dyskretnej:
  E[X] = xâ‚Â·P(X=xâ‚) + xâ‚‚Â·P(X=xâ‚‚) + ... = Î£ xáµ¢ Â· P(X=xáµ¢)
```

**PrzykÅ‚ad â€” rzut kostkÄ…:**

```
E[X] = 1Â·(1/6) + 2Â·(1/6) + 3Â·(1/6) + 4Â·(1/6) + 5Â·(1/6) + 6Â·(1/6)
     = (1 + 2 + 3 + 4 + 5 + 6) / 6
     = 21 / 6
     = 3.5

Interpretacja: jeÅ›li rzucimy kostkÄ… wiele razy, Å›redni wynik bÄ™dzie
zbliÅ¼aÅ‚ siÄ™ do 3.5 (nawet choÄ‡ nikt nie moÅ¼e "wyrzuciÄ‡ 3.5").
```

**PrzykÅ‚ad â€” loteria:**

```
Loteria: kupisz bilet za 5 zÅ‚. Z prawdopodobieÅ„stwem 0.001 wygrywasz 1000 zÅ‚.
Z prawdopodobieÅ„stwem 0.999 nie wygrywasz nic.

E[wygrana] = 1000 Ã— 0.001 + 0 Ã— 0.999 = 1 zÅ‚

KupiÅ‚eÅ› bilet za 5 zÅ‚, a wartoÅ›Ä‡ oczekiwana wygranej to 1 zÅ‚.
Matematycznie to zÅ‚y interes! (-4 zÅ‚ oczekiwanej straty)
```

### Wariancja i odchylenie standardowe

**Wariancja** mierzy, jak bardzo wyniki sÄ… rozrzucone wokÃ³Å‚ wartoÅ›ci oczekiwanej.

```
Var[X] = E[(X - Î¼)Â²] = Î£ (xáµ¢ - Î¼)Â² Â· P(X = xáµ¢)

Gdzie Î¼ = E[X]
```

Obliczenie step-by-step dla rzutu monetÄ… (0 = reszka, 1 = orzeÅ‚, p=0.5):

```
Î¼ = E[X] = 0 Ã— 0.5 + 1 Ã— 0.5 = 0.5

Var[X] = (0 - 0.5)Â² Ã— 0.5 + (1 - 0.5)Â² Ã— 0.5
       = 0.25 Ã— 0.5 + 0.25 Ã— 0.5
       = 0.125 + 0.125
       = 0.25
```

**Odchylenie standardowe** = pierwiastek z wariancji:

```
Ïƒ = âˆšVar[X] = âˆš0.25 = 0.5
```

Dlaczego liczymy pierwiastek? Bo wariancja jest w jednostkach "kwadratowych" (np. metryÂ²), a odchylenie standardowe jest w tych samych jednostkach co dane (metry).

---

## âœ… SprawdÅº siÄ™ â€” CzÄ™Å›Ä‡ Matematyczna

1. Rzucamy kostkÄ…. Oblicz P(wypadnie liczba nieparzysta).
2. Oblicz P(A lub B) gdzie P(A) = 0.3, P(B) = 0.4, P(A i B) = 0.1.
3. 60% studentÃ³w zdaÅ‚o egzamin z matematyki, 70% z fizyki, 45% zdaÅ‚o oba. Jaka jest szansa, Å¼e student wylosowany losowo zdaÅ‚ matematykÄ™, wiedzÄ…c Å¼e zdaÅ‚ fizykÄ™?
4. Oblicz wartoÅ›Ä‡ oczekiwanÄ… i odchylenie standardowe rzutu kostkÄ….

<details>
<summary>Odpowiedzi</summary>

1. Liczby nieparzyste: {1, 3, 5} â†’ P = 3/6 = 0.5

2. P(A lub B) = 0.3 + 0.4 - 0.1 = 0.6

3. P(mat | fiz) = P(mat i fiz) / P(fiz) = 0.45 / 0.70 â‰ˆ 0.643 (64.3%)

4. E[X] = (1+2+3+4+5+6)/6 = 3.5
   Var[X] = [(1-3.5)Â²+(2-3.5)Â²+(3-3.5)Â²+(4-3.5)Â²+(5-3.5)Â²+(6-3.5)Â²]/6
          = [6.25+2.25+0.25+0.25+2.25+6.25]/6 = 17.5/6 â‰ˆ 2.917
   Ïƒ = âˆš2.917 â‰ˆ 1.71

</details>

---

---

# CZÄ˜ÅšÄ† II: JAK TO DZIAÅA W AI?

> Zarys zastosowaÅ„ â€” nie musisz teraz rozumieÄ‡ wszystkich szczegÃ³Å‚Ã³w.

---

### Dlaczego AI uÅ¼ywa prawdopodobieÅ„stwa?

WyobraÅº sobie, Å¼e budujesz program do rozpoznawania zdjÄ™Ä‡. Pokazujesz mu zdjÄ™cie i program musi stwierdziÄ‡: "to jest kot" lub "to jest pies".

Gdyby program po prostu odpowiadaÅ‚ "kot" albo "pies" â€” nie wiedzielibyÅ›my jak pewna jest ta odpowiedÅº. A to jest waÅ¼ne!

Znacznie lepiej, gdyby program odpowiadaÅ‚: "**87% pewnoÅ›ci, Å¼e to kot, 13% pewnoÅ›ci, Å¼e to pies**".

To wÅ‚aÅ›nie robi wiÄ™kszoÅ›Ä‡ programÃ³w AI â€” zamiast jednej kategorycznej odpowiedzi, zwraca **rozkÅ‚ad prawdopodobieÅ„stwa** po wszystkich moÅ¼liwych wynikach.

### PrawdopodobieÅ„stwo jako wynik modelu

Na najniÅ¼szym poziomie, program AI bierze dane wejÅ›ciowe i po serii obliczeÅ„ produkuje liczby. Te liczby sÄ… potem zamieniane na prawdopodobieÅ„stwa. Suma prawdopodobieÅ„stw musi wynosiÄ‡ 1 (bo jedno z moÅ¼liwych wydarzeÅ„ na pewno nastÄ…pi).

```
PrzykÅ‚ad â€” rozpoznawanie pisma:
WejÅ›cie: zdjÄ™cie cyfry

WyjÅ›cie modelu (przed zamienieniem na prawdopodobieÅ„stwa):
  [0.1, 5.2, 0.3, 0.2, 1.1, 0.0, 0.3, 0.1, 0.4, 0.2]
  dla cyfr: 0    1    2    3    4    5    6    7    8    9

Po zamianie na prawdopodobieÅ„stwa:
  [1%, 87%, 2%, 1%, 5%, 0%, 1%, 0%, 2%, 1%]

Model mÃ³wi: "87% szansy Å¼e to jedynka"
```

Jak dokÅ‚adnie ta zamiana wyglÄ…da â€” matematycznie â€” poznasz kiedy bÄ™dziesz gÅ‚Ä™biej w kursie (to funkcja softmax, ktÃ³rÄ… robiliÅ›my w lekcji o logarytmach).

### Twierdzenie Bayesa â€” aktualizowanie wiedzy

Twierdzenie Bayesa jest przydatne zawsze gdy mamy "stare przekonanie" i "nowy dowÃ³d".

```
PrzykÅ‚ad intuicyjny (bez wzorÃ³w):

Zaczynasz od "50/50 â€” nie wiem czy ten email to spam".

Potem patrzysz: email zawiera sÅ‚owo "WYGRAÅEÅš NAGRODÄ˜".
W 90% przypadkÃ³w takie emaile to spam.

Bayes mÃ³wi: "Zaktualizuj przekonanie. Teraz spam jest duÅ¼o bardziej prawdopodobny."

Wynik: 95% szansy Å¼e to spam.
```

Programy do filtrowania spamu dziaÅ‚ajÄ… dokÅ‚adnie na tej zasadzie â€” analizujÄ… sÅ‚owa w emailu i stopniowo aktualizujÄ… "podejrzenie o spam".

SzczegÃ³Å‚y matematyczne tego jak jest to uÅ¼ywane w konkretnych algorytmach poznasz w kolejnych krokach kursu.

---

## ğŸ“Œ Podsumowanie

| PojÄ™cie | Co to? |
|---------|--------|
| **PrawdopodobieÅ„stwo** | Liczba 0-1 opisujÄ…ca "moÅ¼liwoÅ›Ä‡" zdarzenia |
| **PrzestrzeÅ„ prÃ³bna Î©** | ZbiÃ³r wszystkich moÅ¼liwych wynikÃ³w |
| **P(A\|B)** | PrawdopodobieÅ„stwo A pod warunkiem B |
| **NiezaleÅ¼noÅ›Ä‡** | A i B niezaleÅ¼ne gdy `P(A i B) = P(A) Ã— P(B)` |
| **Twierdzenie Bayesa** | Aktualizacja wiedzy: `P(A\|B) = P(B\|A)Â·P(A)/P(B)` |
| **RozkÅ‚ad normalny** | Krzywa dzwonowa; parametry: Å›rednia Î¼, odch. std. Ïƒ |
| **WartoÅ›Ä‡ oczekiwana** | "PrzeciÄ™tna" wartoÅ›Ä‡: `E[X] = Î£ xáµ¢ Â· P(xáµ¢)` |
| **Wariancja** | Rozrzut wokÃ³Å‚ Å›redniej: `Var[X] = E[(X-Î¼)Â²]` |
